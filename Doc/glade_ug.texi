\input texinfo @c -*-texinfo-*-
@setfilename glade_ug.info
@settitle GLADE User's Guide
@setchapternewpage odd
@syncodeindex fn cp

@titlepage

@title GLADE User's Guide
@subtitle GLADE, GNAT Library for Ada Distributed Environment
@subtitle Version 2.01 (DRAFT)
@subtitle December 16, 1997
@author Laurent Pautet, Samuel Tardieu

@page
@vskip 0pt plus 1filll

@copyright{} Copyright 1997-1998, Free Soft Foundation.

GLADE is free software; you can redistribute it and/or modify it under
terms of the GNU General Public License as published by the Free
Software Foundation; either version 2, or (at your option) any later
version. GNAT is distributed in the hope that it will be useful, but
WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANT
ABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
License for more details.  You should have received a copy of the GNU
General Public License along with GNAT; see file COPYING. If not, write
to the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.

@end titlepage

@ifinfo
@node Top, About This Guide, (dir), (dir)
@top GLADE User Guide

GLADE is the GNAT implementation of Distributed Systems Annex.

@end ifinfo

@menu
* About This Guide::            
* Introduction to Distributed Systems::  
* The Distributed Systems Annex::  
* Getting Started With GLADE::  
* DSA and CORBA::               
@end menu

@node About This Guide, Introduction to Distributed Systems, Top, Top
@unnumbered About This Guide

@menu
* What This Guide Contains::    
@end menu

@node What This Guide Contains,  , About This Guide, About This Guide
@unnumberedsec What This Guide Contains

@noindent
This guide contains the following chapters:

@itemize @bullet
@item
@ref{Introduction to Distributed Systems}, describes different ways to
develop distributed systems.

@item
@ref{The Distributed Systems Annex}, describes the different features
available in Annex E of Ada 95. This chapter provides a tutorial for
beginners and includes several useful examples for more advanced
programmers.

@item
@ref{Getting Started With GLADE}, describes how to use the configuration 
tool Gnatdist. It also provides several useful information on GLADE
Partition Communication Subsystem, GARLIC.

@item
@ref{DSA and CORBA}, is a quite fair comparison between CORBA and the
Distributed System Annex.

@end itemize

@node   Introduction to Distributed Systems, The Distributed Systems Annex, About This Guide, Top
@chapter Introduction to Distributed Systems

A distributed system architecture comprises a network of computers and the
software components that execute on the computers. Such architectures are
commonly used to improve the performance, reliability, and reusability of
complex applications. Typically, when there is no shared address space
available to remotely-located components, components must communicate using
some form of message-passing abstraction.


@menu
* Using OS Network Services::   
* Using a Middleware Environment::  
* Using a Distributed Language::  
@end menu

@node Using OS Network Services, Using a Middleware Environment, Introduction to Distributed Systems, Introduction to Distributed Systems
@section Using OS Network Services

There are several programming techniques for developing distributed
applications. These applications have traditionally been developed using
network programming interfaces such as sockets. Programmers explicitly
have to perform calls to operating system services, a task that can be
tedious and error-prone. This includes initializing socket connection
and determining peer location, marshaling and unmarshaling data
structures, sending and receiving messages, debugging and testing
several programs at the same time and porting on several platforms to
hide subtle differences between various network interfaces.

Of course, this code can be encapsulated in wrappers to reduce its
complexity but it is clear that most of it can be automatically
generated. Message passing diverts developer's attention from the
application domain. The query and reply scenario is a classical scheme
in distributed applications; using message passing in such a situation
could be compared to using a ``goto'' mechanism in a non-distributed
application.  This is known to be a significant problem in the domain of
modern programming languages. A more robust design would be to use a
structured approach based on procedure call.

In some respects, this network programming issue can be compared to the
multi-threading programming issue. An user can decide to split his code
in several pieces and to multiplex the thread executions himself using a
table-driven model. The scheduling code would be embedded into the user
code. This solution is error-prone and fragile in regard to any future
modification.

@node Using a Middleware Environment, Using a Distributed Language, Using OS Network Services, Introduction to Distributed Systems
@section Using a Middleware Environment

A middleware environment is intended to provide high level abstractions
in order to easily develop user applications.  Environments like CORBA
or Distributed Computing Environment (DCE) propose an approach to
develop client/server applications using the Remote Procedure Call model
(RPC). The RPC model is inspired from the query and reply
scheme. Compared to a regular procedure call, arguments are pushed into
a stream along with some data pointing out which remote procedure is to
be used and the stream is transmitted over the network to the
server. The server decodes the stream, does the regular subprogram call,
then put the output parameters into another stream along with the
exception (if any) raised by the subprogram and sends this stream back
to the caller. The caller decodes the stream and raises the exception if
needed.

CORBA provides the same enhancements to the remote procedure model that
object languages provide to classical procedural languages.  This also
includes encapsulation, inheritance, type checking, and
exceptions. These features are offered through an Interface Definition
Language (IDL).

The middleware communication framework provides all the machinery to
perform, somewhat transparently, remote procedure calls or remote object
method invocations. For instance, each CORBA interface communicates
through an Object Request Broker (ORB). A communication subsystem such
as an ORB is intended to allow applications to use objects without being
aware of their underlying message passing implementation. But the user
may also require a large number of complex services to develop the
distributed application. Some of them are definitively needed like a
location service that allows clients to reference remote services via
higher level names instead of a traditional scheme for addressing remote
services involving Internet host addresses and communication port
number. Other services provide domain independent interfaces that are
frequently used by distributed applications like naming services.

If we get back to the multi-thread programming comparison, the
middleware solution is close to what a POSIX library or a language like
Esterel would propose to develop a concurrent application. A middleware
framework like DCE is close to a POSIX library in terms of abstraction
levels. Functionalities are very low-level and very complex. CORBA is
closer to Esterel in terms of development process.  The control part of
the application can be specified in a description language. The
developer then has to fill in automatically generated source code (stub
and skeletons) to call the computation part of the application. The
distribution is a pre-compilation process and the distributed boundaries
are always explicit. Using CORBA, the distributed part is written in IDL
and the core of the application is written in a host language.

@node Using a Distributed Language,  , Using a Middleware Environment, Introduction to Distributed Systems
@section Using a Distributed Language

Rather than defining a new language like an IDL, an alternative idea is
to extend a programming language in order to provide distributed
features. The distributed object paradigm provides a more
object-oriented approach to programming distributed systems. The notion
of a distributed object is an extension to the abstract data type that
permits the services provided in the type interface to be called
independently of where the actual service is executed. When combined
with object-oriented features such as inheritance and polymorphism,
distributed objects promote a more dynamic and structured computational
environment for distributed applications.

Ada95 includes a Distributed Systems Annex (DSA) which defines several
extensions allowing a user to write a distributed system entirely in
Ada, using Ada packages as the definition of remote procedure call or
remote method call on distributed objects. Ada95 distributed systems
model is close to Modula-3's one and Java/RMI's one is similar to
Ada95's one. In these languages, the IDL is replaced by a subset of the
language. Therefore, the language supports both remote procedure calls
and remote object method invocations transparently.

A program written in such a language is supposed to communicate with a
program written in the same language, but this restriction gives rise to
several useful consequences. The language can provide more powerful
features because it is not constrained by the common features available
in all host languages. In Ada95, the user will define a specification of
remote services and implement them exactly as he would for ordinary,
non-distributed services. His Ada95 environment will compile them to
produce a stub file (on the caller side) and a skeleton file that
automatically includes the services body (on the receiver
side). Creating objects, obtaining or registering object references or
adapting the object skeleton to the user object implementation are made
transparent because the language environment has a full control on the
development process.

Comparing with multi-thread programming once again, the language
extension solution is equivalent to the solution adopted for tasking
facilities in Ada.  Writing a distributed application is as simple as
writing a concurrent application: there is no binding consideration and
no code to wrap.  The language and its run-time system take care of
every issue that would divert the programmer's attention from the
application domain.

@node The Distributed Systems Annex, Getting Started With GLADE, Introduction to Distributed Systems, Top
@chapter The Distributed Systems Annex

The basic idea of the Distributed Systems Annex (DSA) is to allow a user
to develop his application the same way whether this application is
going to be executed as several programs on a distributed system or as a
whole program on a non-distributed system. The DSA has been designed so
as to minimize the changes required to the source code of a program, in
converting it from an ordinary non-distributed program, to a distributed
program.

The easiest way to start with DSA is certainly to develop the
application on a non-distributed system. Of course, the design of the
application should take into account the fact that some units are going
to be accessed remotely. In order to write an Ada95 distributed program,
it is necessary for the user to categorize certain library level
compilation units of the application program, by inserting
categorization pragmas into their specification. The units which require
categorization are typically those which are called remotely, or ones
which provide types used in remote calls.

Therefore, these units must contain only a restricted set of Ada
entities. For instance, if the distributed system has no shared memory,
shared variables should be forbidden. To ensure such restrictions, the
DSA provides several categorization pragmas in order to reduce the set
of entities one can declare in a given unit.

Of course, you can develop the non-distributed application with your
usual software engineering environment. This is very important to note
that the user needs no specialized tools to develop his/her distributed
application. For instance, he can debug his/her application with his/her
usual debugger. A non-distributed program is not to be confused with a
distributed application composed of only one program. The later is built
with the help of the configuration tool and includes the communication
library.

The last step is to partition and to configure the non-distributed
application into a distributed application, that means multiple
partitions working cooperatively as part of a single Ada program. The
process of mapping the partitions of a program to the nodes in a
distributed system is called configuring the partitions of the
program. This is what GLADE is for.

The distributed version of the user application should work as is, but
even when a program can be built either as a non-distributed or a
distributed program using the same source code, there may still be
differences in program execution between the distributed and
non-distributed versions. These differences will be presented in others
sections.

Developping a non-distributed application in order to distribute it
later on is the natural approach for a novice. Of course, it is not
always possible to write a distributed application as a non-distributed
application. For instance, a client/server application does not belong
to this category because several instances of the client can be active
at the same time. It is very easy to develop such an application using
GLADE and we shall present to the expert how to do that in the following
sections.



@menu
* Architecture of a Distributed Ada95 Application::  
* Categorization Pragmas::      
* Pragma Remote_Call_Interface::  
* Pragma Remote_Types::         
* Pragma Shared_Passive::       
* Overview of Pragma Pure::     
* More About Categorization Pragmas::  
* Marshalling and Unmarshalling Operations::  
* Most Features in One Example::  
@end menu

@node Architecture of a Distributed Ada95 Application, Categorization Pragmas, The Distributed Systems Annex, The Distributed Systems Annex
@section Architecture of a Distributed Ada95 Application

A distributed system is an interconnection of one or more processing
nodes and zero or more storage nodes. A distributed program comprises
one or more partitions. A partition is an aggregate of library
units. Partitions communicate through shared data or RPCs. A passive
partition has no thread of control. Only a passive partition can be
configured on a storage node. An active partition has zero or more
threads of control and has to be configured on a processing node.

The library unit is the core component of an Ada95 distributed
application. The user can explicitly assign library units to a
partition. The partitioning is a post-compilation process. The user
identifies at compile time interface packages. These packages are
categorized using pragmas. Each of these pragmas allows to use one of
the following classical paradigms:

@itemize @bullet
@item Remote subprograms:
For the programmer, a remote subprogram call is similar to a regular
subprogram call. Run-time binding using access-to-subprogram types can
also be used with remote subprograms. These remote subprograms are
mostly declared in library units categorized as remote call interface
(RCI).
  
@item Distributed objects:
Particular access types can be defined, which designate remote
objects. When a primitive dispatching operation is invoked on an object
designated by a remote access, a remote call is performed transparently
on the partition on which the object was created. These distributed
objects are declared in library units categorized as remote types (RT).
  
@item Shared objects:
Global data can be shared between active partitions, providing a
repository similar to a shared memory, a shared file system or a
database. Entry-less protected objects allow safe access and update on
shared objects. This feature is orthogonal to the notion of distributed
objects, which are only accessed through exported services. These shared 
objects are declared in library units categorized as shared passive (SP).

@end itemize

The remotely-called subprograms declared in a library unit categorized
as remote call interface (RCI) or remote types (RT) may be either
statically or dynamically bound. The partition on which a statically
bound remote subprogram is executed can be determine before the
call. This is a regular remote subprogram call. A remote method or a
dereference of access to remote subprogram are dynamically bound remote
calls because the partition on which the remote subprogram is executed
is determined by the parameters of the call.

In the following example, Data_1 and Data_2 are shared passive (SP)
library units. Data_1 is configured on a passive partition mapped on a
storage node. Partition_1 and Partition_2 are active partitions. Note
that under some circumstances, a partition, for instance Partition_2,
can be duplicated. To be duplicated, Unit_2 and Unit_3 which are
configured on Partition_2 have to provide only dynamically bound remote
subprograms. Otherwise, a partition calling a remote subprogram on
Unit_2 would not be able to statically determine where to perform the
remote call.
 
@image{xe-arch.fig}

@node Categorization Pragmas, Pragma Remote_Call_Interface, Architecture of a Distributed Ada95 Application, The Distributed Systems Annex
@section Categorization Pragmas

Library units can be categorized according to the role they play in a
distributed program. A categorization pragma is a library unit pragma
that restricts declarations, child units or semantic dependences of the
library unit to which it applies. There are several categorization
pragmas :

@itemize @bullet
@item Remote_Call_Interface
@item Remote_Types
@item Shared_Passive
@item Pure
@end itemize

The following paragraphs do not present the detailed semantics of these
pragmas. Their purpose is to give to the reader an intuitive overview of
what these pragmas are for. When a library unit is not categorized, this
unit is called a normal unit and cannot play a role in the distributed
application. Such a unit is duplicated on any partition in which it is
involved.

As a general remark, to avoid the development of a specific run-time
library for the DSA, the notion of remote rendez-vous has not been
introduced in Ada95. Therefore, task types and general protected types
are not allowed in the following Ada library units.


@node Pragma Remote_Call_Interface, Pragma Remote_Types, Categorization Pragmas, The Distributed Systems Annex
@section Pragma Remote_Call_Interface



@menu
* Overview of Pragma Remote_Call_Interface::  
* Regular Remote Subprograms (RCI)::  
* Remote Access to Subprograms (RAS)::  
* Remote Access to Class Wide Types (RACW)::  
* Summary on Pragma Remote_Call_Interface::  
@end menu

@node Overview of Pragma Remote_Call_Interface, Regular Remote Subprograms (RCI), Pragma Remote_Call_Interface, Pragma Remote_Call_Interface
@subsection Overview of Pragma Remote_Call_Interface

Library units categorized with this pragma can declare subprograms to be
called and executed remotely.  This classical RPC operation is a
statically bound operation. In these units, clients and servers do not
share their memory space.

Dynamically bound calls are integrated with Ada capabilities to
dereference subprograms (remote access to subprogram - RAS) and to
dispatch on access-to-class-wide operands (remote access on class wide
types - RACW). These remote access types can be declared in a RCI
package as well.

A remote access type (RAS or RACW) can be viewed as a fat pointer or a
structure with a remote address and a local address (like an URL). The
remote address describes for instance the host on which the entity has
been created; the local address describes the classical local memory
address.

@node Regular Remote Subprograms (RCI), Remote Access to Subprograms (RAS), Overview of Pragma Remote_Call_Interface, Pragma Remote_Call_Interface
@subsection Regular Remote Subprograms (RCI)

In the following example, a RCIBank offers several remote services:
Balance, Transfert, Deposit and Withdraw. On the caller side, the bank
client will use the stub files of unit RCIBank. On the receiver side,
the bank receiver will use the skeleton files of unit RCIBank including
the body of this package.

@include types.ads.texi
@include rcibank.ads.texi
@include rciclient.adb.texi

@node Remote Access to Subprograms (RAS), Remote Access to Class Wide Types (RACW), Regular Remote Subprograms (RCI), Pragma Remote_Call_Interface
@subsection Remote Access to Subprograms (RAS)

In the following example, several mirroring banks offer their
services. Each bank registers a reference to each of its services to a
central bank. A central bank client asks for a service of one of the
mirroring banks. In this purpose, the RCI unit RASBank defines
Balance_Type, a remote access to subprogram. An access type in a remote
unit has to be either remote access to subprogram or remote access to
class wide type.

Note that to get a remote access to subprogram the subprogram has to be
remote itself. Therefore, MirrorBank is a RCI library unit.

@include rasbank.ads.texi

In the code below, a mirroring bank registers its services to the
central bank.

@include mirrorbank.ads.texi
@include mirrorbank.adb.texi

In the code below, a central bank client asks for a mirroring bank and
calls the Balance service of this bank by dereferencing a remote access
type.

@include bankclient.adb.texi


@node Remote Access to Class Wide Types (RACW), Summary on Pragma Remote_Call_Interface, Remote Access to Subprograms (RAS), Pragma Remote_Call_Interface
@subsection Remote Access to Class Wide Types (RACW)

A bank client is now connected to a bank through a terminal. The bank
wants to notify a connected client with a message on its terminal when
another client grants him with a given amount of money.

@include terminal.ads.texi

In the code below, the RCI unit RACWBank defines Term_Access, a remote
access to class wide type. Term_Access becomes a reference to a
distributed object. In the next section, we will see how to derive
Term_Type, how to create a distributed object and how to use a reference
to it.

@include racwbank.ads.texi

@node Summary on Pragma Remote_Call_Interface,  , Remote Access to Class Wide Types (RACW), Pragma Remote_Call_Interface
@subsection Summary on Pragma Remote_Call_Interface

Remote call interface units:

@itemize @bullet
@item
Allow subprograms to be called and executed remotely

@item
Allow statically bound remote calls (remote subprogram)

@item
Allow dynamically bound remote calls (remote access types)

@item
Forbid variables and non-remote access types

@item
Prevent specification from depending on normal units

@end itemize


@node Pragma Remote_Types, Pragma Shared_Passive, Pragma Remote_Call_Interface, The Distributed Systems Annex
@section Pragma Remote_Types



@menu
* Overview of Pragma Remote_Types::  
* Distributed Object::          
* Transmitting Dynamic Structure::  
* Summary on Remote Types Units::  
@end menu

@node Overview of Pragma Remote_Types, Distributed Object, Pragma Remote_Types, Pragma Remote_Types
@subsection Overview of Pragma Remote_Types

Unlike RCI units, library units categorized with this pragma can define
distributed objects and remote methods on them. Both RCI and RT units
can define a remote access type described above (RACW). A subprogram
defined in a RT unit is not a remote subprogram. Unlike RCI units, a RT
unit can be duplicated on several partitions in which case all its
entities are different with each other. This unit is different on each
partition in which it is defined.

@node Distributed Object, Transmitting Dynamic Structure, Overview of Pragma Remote_Types, Pragma Remote_Types
@subsection Distributed Object

If we want to implement the notification feature proposed in the
previous section, we have to derive Term_Type. Such a derivation is
possible in a remote types unit, NewTerminal. Any object of type
New_Term_Type becomes a distributed object and any reference to such an
object becomes a fat pointer or a reference to a distributed object.

@include newterminal.ads.texi

In the code below, a client registers his terminal to
RACWBank. Therefore, when any donator grants him with a given amount of
money, RACWBank is able to notify this client of the granting operation.

@include term2client.adb.texi

In the code below, a second client, the donator, registers his terminal
to the bank and executes a transfer to the first client.

@include term1client.adb.texi

In the code below, we describe the general design of Transfer. Classical
operations of Withdraw and Deposit are performed. Then, RACWBank
retrieves the terminal of the granted client and invoke a dispatching
operation by dereferencing a distributed object Term. The reference is
analyzed and the execution of this operation occurs on the partition to
which the distributed object belongs.

@include racwbank.adb.texi

@node Transmitting Dynamic Structure, Summary on Remote Types Units, Distributed Object, Pragma Remote_Types
@subsection Transmitting Dynamic Structure

@include stringarraystream.ads.texi

General access types are forbidden in public part of a remote types
unit. But this would be too restrictive. It is possible to define
private general access types as long as the user provides its
marshalling procedures. The code below describes how to transmit a
linked structure.

The code below provides an implementation of the marshalling operations
defined above:

@include stringarraystream.adb.texi


@node Summary on Remote Types Units,  , Transmitting Dynamic Structure, Pragma Remote_Types
@subsection Summary on Remote Types Units

Remote types units:

@itemize @bullet
@item
Allow to define distributed objects

@item
Allow dynamically bound remote calls (remote access type)

@item
Allow general access type (with marshalling subprograms)

@c @item
@c Allow unit duplication (like normal units)

@item
Prevent specification from depending on normal units

@end itemize

@node Pragma Shared_Passive, Overview of Pragma Pure, Pragma Remote_Types, The Distributed Systems Annex
@section Pragma Shared_Passive



@menu
* Overview of Pragma Shared_Passive::  
* Summary on Pragma Shared_Passive::  
@end menu

@node Overview of Pragma Shared_Passive, Summary on Pragma Shared_Passive, Pragma Shared_Passive, Pragma Shared_Passive
@subsection Overview of Pragma Shared_Passive

The entities declared in such categorized unit library are to be mapped
on a virtual shared address space (file, memory, database). When two partitions
use such a library unit, they can communicate by reading or writing the
same variable. This supports the shared variables paradigm. Entryless
protected objects declared in these units provide an atomic access to
some shared data, thus implementing a transaction mechanism.

@subsection Shared and Protected Objects

In the code below, we define two kinds of shared
objects. External_Synchronization requires that the different partitions
updating this data synchronize to avoid conflicting operations on shared
objects. Internal_Synchronization provides a way to get an atomic
operation on shared objects. Note that only entry-less subprograms are
allowed in a shared passive unit.

@include sharedobjects.ads.texi

@node Summary on Pragma Shared_Passive,  , Overview of Pragma Shared_Passive, Pragma Shared_Passive
@subsection Summary on Pragma Shared_Passive

@itemize @bullet
@item
Allow direct access to data among different partitions

@item
Allow support on shared (distributed) memory

@item
Allow memory protection use for entryless protected objects

@item
Prevent specification from depending on normal units

@end itemize

@node Overview of Pragma Pure, More About Categorization Pragmas, Pragma Shared_Passive, The Distributed Systems Annex
@section Overview of Pragma Pure

This pragma is not specific to the Distributed Systems Annex. But a pure
package can be withed in the specification of any of the other
categorized packages. A pure package is a preelaborable package that
does not contain the declaration of any variable or named access
type. It is particularly useful to define types, constants and
subprograms shared by several categorized packages. Remember that normal
packages cannot be withed in categorized package declarations.

@node More About Categorization Pragmas, Marshalling and Unmarshalling Operations, Overview of Pragma Pure, The Distributed Systems Annex
@section More About Categorization Pragmas



@menu
* Variables and Non-Remote Access Types::  
* RPC Failures::                
* Exceptions::                  
* Pragma Asynchronous::         
* Pragma All_Calls_Remote::     
* Generic Categorized Units  ::  
* Categorization Unit Dependencies::  
@end menu

@node Variables and Non-Remote Access Types, RPC Failures, More About Categorization Pragmas, More About Categorization Pragmas
@subsection Variables and Non-Remote Access Types

In RT or RCI package declarations, variables are forbidden and general
access types are allowed as long as their marshaling subprograms are
provided (see section @ref{Transmitting Dynamic Structure}).. 

@node RPC Failures, Exceptions, Variables and Non-Remote Access Types, More About Categorization Pragmas
@subsection RPC Failures

Calls are made at most one time: they are made exactly one time or they
fail with an exception. When an communication error occurs,
@t{System.RPC.Communication_Error} is raised.

@node Exceptions, Pragma Asynchronous, RPC Failures, More About Categorization Pragmas
@subsection Exceptions

Any exception raised in a remote
method or subprogram call is propagated back to the caller. Exceptions
semantics are preserved in the regular Ada way.

@include internal.ads.texi
@include rempkg2.ads.texi
@include rempkg1.ads.texi

Let us say that RemPkg2, Internal and RemExcMain packages are on the same
partition Partition_1 and that RemPkg1 is on partition Partition_2.

@include rempkg2.adb.texi
@include rempkg1.adb.texi
@include remexcmain.adb.texi

When RemPkg1.Subprogram on Partition_1 raises Internal.Exc, this
exception is propagated back to Partition_2. As Internal.Exc is not defined
on Partition_2, it is not possible to catch this exception without an
exception handler @b{when others}. When we reraise this exception in
RemPkg1.Subprogram, it is propagated on Partition_1. But this time,
Internal.Exc is defined and can be handled as we would in a regular Ada
program. Of course, the exception message is also preserved.
  
@c XXXX Schema Sam exceptions

@node Pragma Asynchronous, Pragma All_Calls_Remote, Exceptions, More About Categorization Pragmas
@subsection Pragma Asynchronous

A pragma Asynchronous allows statically and dynamically bound remote
calls to be executed asynchronously. An asynchronous procedure doesn't
wait for the completion of the remote call and lets the caller continue
its execution path. This allows a calling task to proceed without
waiting for callee procedure to complete. The procedure must have only
@b{in} parameters and any exception raised during the execution of the
remote procedure is lost. Of course, this precludes exception
propagation of remotely called procedure.

When pragma Asynchronous applies to a regular subprogram with @b{in}
parameters, any call to this subprogram will be executed
asynchronously. Declaration of AsynchronousRCI.Asynchronous gives an
example.

@include asynchronousrci.ads.texi
@include asynchronousrt.ads.texi

@c XXXXX Check this
A pragma Asynchronous applies to a RAS. An asynchronous RAS can be both
asynchronous and synchronous depending on the designated subprogram. For
install, in the code below, remote call (1) is asynchronous but remote
call (2) is synchronous.

A pragma Asynchronous applies to a RACW as well. In this case, the
invocation of @b{any} method with in parameters is @b{always} performed
asynchronously. Remote method invocation (3) is asynchronous when remote
method invocation (4) is synchronous.

@include asynchronousmain.adb.texi

This feature allows message passing programming. But the user has to
realize that message passing programming, and asynchronous remote calls
in particular, has several drawbacks:

@itemize @bullet

@item
Violate original (remote) procedure semantics

@item
Allow some kind of remote GOTO mechanism

@item
Prevent easy development and debugging in a non-distributed context

@item
Introduce potential race conditions

@end itemize

To illustrate the latter, let us take the following example:

@include node2.ads.texi
@include node2.adb.texi
@include node1.ads.texi
@include node1.adb.texi
@include nondeterministic.adb.texi

Let us say that Main is configured on Partition_0, Node1 on Partition_1
and Node2 on Partition_2. If Node1.Send and Node2.Send procedures were
synchronous or if no latency was introduced during network
communication, we would have the following RPC order: Main remotely
calls Node1.Send which remotely calls Node2.Send which sets V to
1. Then, Main remotely calls Node2.Send and sets V to 2.

Now, let us assume that both Send procedures are asynchronous and that
the connection between Partition_1 and Partition_2 is very slow. The
following scenario can very well occur. Main remotely calls Node1.Send
and is unblocked. Immediatly after this call, Main remotely calls
Node2.Send and sets V to 2. Once this is done, the remote call to
Node1.Send completes on Partition_1 and it remotely calls Node2.Send
which sets V to 1.

@node Pragma All_Calls_Remote, Generic Categorized Units  , Pragma Asynchronous, More About Categorization Pragmas
@subsection Pragma All_Calls_Remote

A pragma All_Calls_Remote in a RCI unit forces remote procedure
calls to be routed through the communication subsystem even for a local
call. This eases the debugging an application in a non-distributed
situation that is very close to the distributed one.

@node Generic Categorized Units  , Categorization Unit Dependencies, Pragma All_Calls_Remote, More About Categorization Pragmas
@subsection Generic Categorized Units  

@include genericrci.ads.texi
@include rciinstantiation.ads.texi
@include normalinstantiation.ads.texi

Any of these categorized units can be generic. Instances of these
generic packages can be either categorized or not. In the latter, such a
unit loses its categorization property. Like any categorized unit, the
generic categorized unit can only be instantiated at the library level
and regular restrictions of categorized units apply on instantiation (in
particular on generic formal parameters).

@node Categorization Unit Dependencies,  , Generic Categorized Units  , More About Categorization Pragmas
@subsection Categorization Unit Dependencies

Each categorization pragma has very specific visibility rules. As a
general rule, RCI > RT > SP > Pure. That means that a
Remote_Types package can make visible in its specification only
Remote_Types, Shared_Passive and Pure units.

@node Marshalling and Unmarshalling Operations, Most Features in One Example, More About Categorization Pragmas, The Distributed Systems Annex
@section Marshalling and Unmarshalling Operations

The PCS marshalls and unmarshalls users data into a stream of type
@t{System.RPC.Params_Stream_Type}:

@smallexample
@b{type} Params_Stream_Type
  (Initial_Size : Ada.Streams.Stream_Element_Count) @b{is new}
    Ada.Streams.Root_Stream_Type @b{with private};
@end smallexample

This type is a container for the data to be transmitted between
partitions. Its root is @t{Root_Stream_Type}, which defines the basic
stream type and two abstract operations, @t{Write} and @t{Read}. Its
purpose is to add / remove objects of type @t{Stream_Element_Array}
which are array of bytes representing a particular data.

Streams are read and written using four attributes:

@itemize @bullet

@item Write: write an element into a stream, valid only for constrained
types

@item Read: read a constrained element from a stream

@item Output: same as Write, but write bounds and discriminants as well
if needed

@item Input: same as Read, but read bounds and discriminants from
  the stream (the Input attribute denotes a function)
@end itemize

An Ada compiler provides default 'Read and 'Write operations. But it is
up to the compiler to provide default 'Read and 'Write to ensure proper
operation between heterogeneous architectures (see @ref{Heterogeneous
Systems}).

The user can overload these operations except for predefined
types. Overloading with a textual version provides the user with a way
to debug its application (even outside of the Distributed Systems
Annex).

@include new_integers.ads.texi
@include new_integers.adb.texi

The language forces the user to provide read and write opertions for non
remote access types. Transmitting an access value by dumping its content
into astream makes no sense when it is going to be transmitted to
another partition (different memory spaces). To transmit non remote
access types see section @ref{Transmitting Dynamic Structure}.
 
@node Most Features in One Example,  , Marshalling and Unmarshalling Operations, The Distributed Systems Annex
@section Most Features in One Example

The example shown on the following figure highlights most of
the features of DSA. The general system is based on a set of factories
and workers and a storage.  Each entity is a partition itself. A
factory hires a worker from a pool of workers (hire - 1) and assigns a
job (query - 2) to him. The worker performs the job and saves the
result (reply - 3) in a storage common to all the factories.  The
worker notifies the factory of the end of his job (notify - 4).

@image{full-ex.fig}
@include storage.ads.texi

When a worker has achieved his job, the result should be saved in a
common storage. To do this, we define a protected area in SP package
Storage (see sample above). Two entry-less protected objects
ensure atomic access on this area.

@include common.ads.texi

Types is a Remote_Types package that defines most of the remote services
of the above system (see sample above). First, we define a way for the
workers to notify the end of his job.  This callback mechanism is
implemented using RAS Notify.

@include newworkers.ads.texi

We define an abstract tagged type Worker which is intended to be the
root type of the whole distributed objects hierarchy. Assign allows a
factory to propose to a worker a job and a way to notify its employer
the end of this job. Any_Worker is a remote access to class wide type
(RACW). In other words, it is a reference to a distributed object of any
derived type from Worker class.

@include newnewworkers.ads.texi

NewWorker is derived from type Worker and Assign is overridden. Sample
above shows how to derive a second generation of workers NewNewWorker
from the first generation NewWorker. As mentioned above, this RT package
can be duplicate on several partitions to produce several types of
workers and also several remote workers.

@include workercity.ads.texi

In sample above, we define an unique place where workers wait for
jobs. Workers is a Remote_Call_Interface package with services to hire
and free workers. Unlike Remote_Types packages, Remote_Call_Interface
packages cannot be duplicated.

@include workercity.ads.texi
@include newfactory.ads.texi

In order to use even more DSA features, Factory is defined as a generic
RCI package (see sample above). Any instantiation defines a new factory
(see sample above). To be RCI, this instantiation has to be categorized
once again.

@node Getting Started With GLADE, DSA and CORBA, The Distributed Systems Annex, Top
@chapter Getting Started With GLADE

This chapter describes the usual ways of using GLADE to compile Ada
distributed programs.

@menu
* Introduction to GLADE::       
* How to Configure a Distributed Application with Gnatdist::  
* Gnatdist Command Line Options::  
* Gnatdist Behind the Scenes::  
* The Configuration Language::  
* Tracing Facilities::          
* Remote Shell Notes::          
* Filtering::                   
* Trace/Replay Debugging::      
* Glade File Hierarchy::        
* GLADE Internals::             
@end menu

@node Introduction to GLADE, How to Configure a Distributed Application with Gnatdist, Getting Started With GLADE, Getting Started With GLADE
@section Introduction to GLADE

An Ada 95 distributed application comprises a number of partitions
which can be executed concurrently on the same machine or, and this is
the interesting part, can be distributed on a network of machines.
The way in which partitions communicate is described in Annex E of the
Ada 95 reference manual.

A partition is a set of compilation units which are linked together to
produce an executable binary. A distributed program comprises two or
more communicating partitions.

The distributed systems annex does not describe how a distributed
application should be configured. It is up to the user to define what
are the partitions in his program and on which machines they should be
executed.

The tool gnatdist and its configuration language have been purposely
designed to allow you to partition your program and specify the
machines where the individual partitions are to execute on.

gnatdist reads a configuration file (whose syntax is described below)
and builds several executables, one for each partition. It also takes
care of launching the different partitions (default) and to pass
arguments specific to each partition.

@node How to Configure a Distributed Application with Gnatdist, Gnatdist Command Line Options, Introduction to GLADE, Getting Started With GLADE
@section How to Configure a Distributed Application with Gnatdist

@itemize @bullet

@item
Write a non-distributed Ada application to get familiar with the GLADE
environment. Use the categorization pragmas to specify the packages that
can be called remotely. The Shared_Passive categorization pragma is not
yet implemented. The Remote_Call_Interface and Remote_Types
categorization pragmas are.

@item
When this non-distributed application is working, write a configuration
file that maps your categorized packages onto partitions. Don't forget
to specify the main procedure of your distributed application (see
below).

@item
Type `gnatdist configuration-file'.

@item
Start your distributed application by invoking the start-up shell script
or Ada program (depending on the "pragma Starter" option, see below).

@end itemize

@node Gnatdist Command Line Options, Gnatdist Behind the Scenes, How to Configure a Distributed Application with Gnatdist, Getting Started With GLADE
@section Gnatdist Command Line Options

@smallexample
gnatdist [switches] configuration-file [list-of-partitions]
@end smallexample

The switches of gnatdist are, for the time being, exactly the same as
for gnatmake.  Read the gnatinfo.txt file from the GNAT distribution for
info on these switches. By default gnatdist outputs a configuration
report and the actions performed. The switch -n allows gnatdist to skip
the first stage of recompilation of the non-distributed application.

All configuration files should end with the `.cfg' suffix. There may be
several configuration files for the same distributed application, as you
may want to use different distributed configurations according to your
computing environment.

If a list  of  partitions is provided  on the  command line,  only these
partitions will be  build. In the  following  configuration example, you
can type : gnatdist configuration partition_2 partition_3.

@node Gnatdist Behind the Scenes, The Configuration Language, Gnatdist Command Line Options, Getting Started With GLADE
@section Gnatdist Behind the Scenes

Here is what goes on behind the scenes in gnatdist when building a
distributed application:

@itemize @bullet
@item
Each compilation unit in the program is compiled into an object module
(as in non distributed applications). This is achieved by calling
gnatmake on the sources of the various partitions.  This step can be
skipped by using the -n option.

@item
Stubs are compiled into object modules (a stub is the software that
allows a partition running on machine A to communicate with a partition
running on machine B).  Several timestamp checks are performed to avoid
useless recompilation.

@item
gnatdist performs a number of consistency checks, for instance it
checks that all packages marked as remote call interfaces (RCI, see
LRM annex E) are mapped onto partitions. It also checks that an
RCI package is mapped onto only one partition.

@item
Finally, the executables for each partition in the program are
created. The code to launch partitions is embedded in the main
partition except if another option has been specified (pragma
Starter). In this case, a shell script (or nothing) is generated to
start the partitions on the appropriate machines. This is specially
useful when one wants to write client / server applications where
the number of instances of the partition is unknown.

@end itemize

@node The Configuration Language, Tracing Facilities, Gnatdist Behind the Scenes, Getting Started With GLADE
@section The Configuration Language

The configuration language is "Ada-like". Because of its simplicity,
it is described by means of an example. As the capabilities of GLADE
will evolve, so will this configuration language.



@menu
* Configuration Declaration::   
* Partition Declaration::       
* Partition Main Procedure::    
* Physical Nodes::              
* Boot Server::                 
* Executable Location::         
* Partition Termination::       
* Partition Reconnection::      
* Channel Declaration::         
* Channel and Partition Filter::  
* Version Consistency::         
* Anonymous Tasks Pool::        
* An Example with Most of the Configuration Language Features::  
@end menu

@node Configuration Declaration, Partition Declaration, The Configuration Language, The Configuration Language
@subsection Configuration Declaration

The distribution of an Ada program is described by a single
configuration unit. This configuration unit has a specification part and
an optional body part. A configuration unit is declared as an Ada
procedure would be. The keyword @b{configuration} is reserved for this
purpose.

@smallexample
CONFIGURATION_UNIT ::= 
   @b{configuration} IDENTIFIER @b{is}
      DECLARATIVE_PART
   [@b{begin}
      SEQUENCE_OF_STATEMENTS]
   @b{end} [IDENTIFIER];
@end smallexample

@node Partition Declaration, Partition Main Procedure, Configuration Declaration, The Configuration Language
@subsection Partition Declaration

In the declarative part, the user declares his partitions and can change
their default behavior. gnatdist provides a predefined type
@b{Partition}. The user can declare a list of partitions and can also
initialize these partitions with an initial list of Ada units.

@smallexample
DECLARATIVE_PART ::= @{DECLARATIVE_ITEM@}

DECLARATIVE_ITEM ::= 
   PARTITION_DECLARATION
 | CHANNEL_DECLARATION
 | REPRESENTATION_CLAUSE
 | SUBPROGRAM_DECLARATION
 | PRAGMA

PARTITION_DECLARATION ::= 
   DEFINING_IDENTIFIER_LIST : Partition
      [:= ENUMERATION_OF_ADA_UNITS];

DEFINING_IDENTIFIER_LIST ::=
   DEFINING_IDENTIFIER @{, DEFINING_IDENTIFIER@}

STATEMENT ::=
   IDENTIFIER := ENUMERATION_OF_ADA_UNITS;

SEQUENCE_OF_STATEMENTS ::=
   STATEMENT @{STATEMENT@}
@end smallexample

Once declared, a partition is an empty list of Ada units. The operator
@b{":="} adds the Ada units list on the right side to the current list
of Ada units that are already mapped to the partition. This is a
non-destructive operation. Whether a unit is a relevant Ada unit or not
is checked later on by the back-end of gnatdist. These assignments can
occur in the declarative part as well as in the body part.

@smallexample
ENUMERATION_OF_ADA_UNITS ::= (@{ADA_UNIT @{, ADA_UNIT@}@});
@end smallexample

As gnatdist generates full Ada code in order to build the different
executables, all the Ada keywords have been reserved even if they are
not used in the configuration language.

@node Partition Main Procedure, Physical Nodes, Partition Declaration, The Configuration Language
@subsection Partition Main Procedure

Basically, the distributed system annex helps a user in building a
distributed application from a non-distributed application. The user
can design, implement and test his application in a non-distributed
environment, and then should be able to switch from his
non-distributed case to a distributed case. This two-phase design
approach has several advantages.

For this reason, the configuration language provides a way to declare
the main procedure of the non-distributed application.

@smallexample
procedure MAIN_UNIT is in PARTITION;
@end smallexample

In this case, the partition in which the main procedure has been
mapped will include in its code a call to this main procedure. Other
partitions will have a null body as a main procedure. But the user can
also modify this behavior by providing an alternate main procedure.

@smallexample
@b{procedure} MAIN_PROCEDURE;

@b{for} PARTITION'Main @b{use} MAIN_PROCEDURE;
@end smallexample

In a non-distributed case, the user executes only one main executable
possibly with a name corresponding to the main unit name of his
application. With gnatdist, in a distributed case, a main executable
with a name corresponding to the main unit name is responsible for
starting the entire distributed application. For this reason, the user
can start his application the same way he used to do in the
non-distributed case.

As a default, the main executable is a shell script that starts
one at a time the different partitions on the appropriate remote
machines. But the user may ask for a full Ada starter procedure. The
pragma Starter allows the user to ask for one starter or another.  

@smallexample
@b{type} Method_Type @b{is} (Ada, Shell, None);

@b{pragma} Starter (Method => Method_Type);
@end smallexample

@node Physical Nodes, Boot Server, Partition Main Procedure, The Configuration Language
@subsection Physical Nodes

Logical nodes (or partitions) can be mapped onto physical
nodes. gnatdist default behavior is to ask for themi nteractively. It is
possible to modify the default behavior of all the partitions via an
attribute definition clause applied to the predefined type
@b{Partition}. It is also possible to modify the default behavior of a
given partition via an attribute definition clause applied to the
partition itself.

The host-name can be either a static or dynamic value. In case of a
static value, the expression is a string literal. In case of a dynamic
value, the representation clause argument is a function that accepts a
string as parameter and that returns a string value. When the function
is called, the partition name is passed as parameter and an host-name
is returned.

@smallexample
REPRESENTATION_CLAUSE ::=
   @b{for} IDENTIFIER'Host @b{use} STRING_LITERAL;
 | @b{for} IDENTIFIER'Host @b{use} SUBPROGRAM;
 | @b{for} Partition'Host @b{use} STRING_LITERAL;
 | @b{for} Partition'Host @b{use} SUBPROGRAM;
@end smallexample

The signature of the function should be the following : it takes a
string parameter which corresponds to a partition name. It also returns
a string parameter which corresponds to an host-name. The function
that returns the host-name can be an Ada function (default) or a shell
script. A pragma Import is used to import a function defined in Ada or
in Shell.  

This function is called before launching the partition. Therefore, in
case of load balancing, the function can return the most appropriate
host from among a set of hosts.

@node Boot Server, Executable Location, Physical Nodes, The Configuration Language
@subsection Boot Server

@smallexample
PRAGMA ::=
   @b{pragma} Boot_Server
     (Protocol_Name => String,
      Protocol_Data => String);
@end smallexample

@node Executable Location, Partition Termination, Boot Server, The Configuration Language
@subsection Executable Location

There are several other attributes that can be applied to a
partition. Storage_Dir allows the user to specify in which directory
the partition executable is stored. This can be useful in heterogeneous
systems when the user wants to store executables of the same target in
a given directory. Specifying the directory is also useful if the
partition executable is not directly visible from the user
environment. For instance, when a remote command like @b{rsh} is
invoked, the executable directory has to be present in the user
path. If the Storage_Dir attribute has been specified, the executable
full name is used.

@smallexample
REPRESENTATION_CLAUSE ::=
   @b{for} IDENTIFIER'Storage_Dir @b{use} STRING_LITERAL;
@end smallexample

@node Partition Termination, Partition Reconnection, Executable Location, The Configuration Language
@subsection Partition Termination

@smallexample
TERMINATION_LITTERAL ::= Global_Termination |
                         Local_Termination  |
                         Defered_Termination

REPRESENTATION_CLAUSE ::=
   @b{for} IDENTIFIER'Termination @b{use} TERMINATION_LITERAL;
@end smallexample

As a default, a set of partitions terminates when each partition can
terminate and when no message is waiting for being handled. This
distributed algorithm is activated periodically by the main boot
server.

@itemize @bullet

@item When the global termination policy is selected on a partition,
it terminates as soon as the main boot server asks it to do so. The main
boot server checks periodically whether this can terminate. When all
partitions are ready to terminate, the main boot server sends to each
partition a termination request.

@item The deferred termination policy is very close to the global
termination. The only difference is that when a partition with a
deferred termination policy receives a termination request, it just
ignores it. This policy allows a partition to run forever without
preventing a set of partitions to terminate. This policy is not yet
implemented.

@item When the local termination policy is selected on a partition,
it terminates as soon as the classical Ada termination is detected on
the partition. It means that this partition does not wait for the
termination request of the main boot server.

@end itemize

@node Partition Reconnection, Channel Declaration, Partition Termination, The Configuration Language
@subsection Partition Reconnection

@smallexample
RECONNECTION_LITTERAL ::= Rejected_On_Restart  |
                          Failed_Until_Restart |
                          Wait_Until_Restart

REPRESENTATION_CLAUSE ::=
   @b{for} IDENTIFIER'Reconnection @b{use} RECONNECTION_LITTERAL;
@end smallexample

When no RCI package is configured on a partition, such a partition can
be launched several times without any problem. When one or more RCI
packages are configured on a partition, such a partition cannot be
launched several times. If this partition was launched several times, it
would not be possible to decide which partition instance should execute
a remote procedure call. Note that this problem can occur in other
circumstances - as soon as a RCI package is duplicated.

When a partition crashes or is stopped, one can want to restart this
partition and possibly to restore its state with Shared_Passive
packages. In such a situation, the partition is already defined on other
partitions and possibly defined as a dead partition. Several policies
can be selected:

@itemize @bullet

@item When the reconnection policy of this partition is set to
Reject_On_Restart, the dead partition is kept dead and any attempt to
restart it fails. Any remote call to a subprogram located on this
partition results in a Communication_Error exception.

@item When the reconnection policy of this partition is set to
Failed_Until_Restart, this partition can be restarted. Any remote call
to a subprogram located on this partition results in an exception
Communication_Error as long as this partition has not been restarted. As
soon as the partition is restarted, remote calls to this partition are
executed normally.

@item When the reconnection policy of this partition is set to
Wait_Until_Restart, this partition can be restarted. Any remote call to
a subprogram located on this partition is suspended until this partition
is restarted. As soon as the partition is restarted, remote calls to
this partition are executed normally. The suspended remote procedure
calls to this partition are resumed.


@end itemize

@node Channel Declaration, Channel and Partition Filter, Partition Reconnection, The Configuration Language
@subsection Channel Declaration

@smallexample
CHANNEL_DECLARATION ::= 
   DEFINING_IDENTIFIER_LIST : Channel
      [:= PARTITION_PEER];

PARTITION_PEER ::= (IDENTIFIER, IDENTIFIER);
@end smallexample

@node Channel and Partition Filter, Version Consistency, Channel Declaration, The Configuration Language
@subsection Channel and Partition Filter

@smallexample
REPRESENTATION_CLAUSE ::=
   @b{for} CHANNEL_IDENTIFIER'Filter @b{use} STRING_LITERAL;
 | @b{for} PARTITION_IDENTIFIER'Filter @b{use} STRING_LITERAL;
 | @b{for} Channel'Filter @b{use} STRING_LITERAL;
 | @b{for} Partition'Filter @b{use} STRING_LITERAL;
@end smallexample

@node Version Consistency, Anonymous Tasks Pool, Channel and Partition Filter, The Configuration Language
@subsection Version Consistency

@smallexample
pragma Version (True | False);
@end smallexample

@node Anonymous Tasks Pool, An Example with Most of the Configuration Language Features, Version Consistency, The Configuration Language
@subsection Anonymous Tasks Pool

@smallexample
REPRESENTATION_CLAUSE ::=
   @b{for} PARTITION_IDENTIFIER'Filter @b{use} TASK_POOL_SIZE_ARRAY;
 | @b{for} Partition'Filter @b{use} TASK_POOL_SIZE_ARRAY;
TASK_POOL_SIZE_ARRAY := (POOL_MIN_SIZE, POOL_HIGH_SIZE, POOL_MAX_SIZE);
@end smallexample

@node An Example with Most of the Configuration Language Features,  , Anonymous Tasks Pool, The Configuration Language
@subsection An Example with Most of the Configuration Language Features

Every keyword and construct defined in the configuration language have
been used in the following sample configuration file.

@include myconfig.cfg.texi

@enumerate

@item @b{Line 1}
Typically after having created the following configuration file you
would type:

@smallexample
gnatdist myconfig.cfg
@end smallexample

If you wish to build only certain partitions then list the partitions to
build on the gnatdist command line as follows:

@smallexample
gnatdist myconfig.cfg   partition_2 partition_3
@end smallexample

@item @b{Line 2}
The name of the file prefix must be the same as the name of the
configuration unit, in this example `myconfig.cfg'. The file suffix must
be `cfg'. For a given distributed application you can have as many
configuration files as you wish.

@item @b{Line 5}
Partition 1 contains no RCI package. However, it will contain the main
procedure of the distributed application, called `Master_Procedure' in
this example. If the line `procedure Master_Procedure is in
Partition_1;' was missing Partition 1 would be completely empty. This is
forbidden, a partition has to contain at least one library unit.

gnatdist produces an executable with the name of Master_Procedure
which will starts the various partitions on their host machines in
the background.  The main partition is launched in the foreground.
Note that by killing this main procedure the whole distributed
application is halted.

@item @b{Line 9}
Specify the host on which to run partition 2.

@item @b{Line 13}
Use the value returned by an a program to figure out at execution
time the name of the host on which partition 3 should execute.  For
instance, execute the shell script `best-node' which takes the
partition name as parameter and returns a string giving the name of
the machine on which partition_3 should be launched.

@item @b{Line 15}
Partition 4 contains one RCI package RCI_B5 No host is specified for
this partition. The startup script will ask for it interactively when it
is executed.

@item @b{Line 17}
Specify the directory in which the executables in each partition will be
stored.

@item @b{Line 18}
Specify the directory in which all the partition executables will be
stored. Default is the current directory.

@item @b{Line 21}
Specify the partition main subprogram to use in a given partition.

@item @b{Line 23}
Specify a reconnection policy on Partition_3 crash. Any attempt to
reconnect to Partition_3 when this partition is dead will be kept
blocking until Partition_3 restart. As a default, any restart is
rejected (Rejected_ON_Restart). Another policy is to raise
Communication_Error on any reconnection attempt until Partition_3 has
been restarted.

@item @b{Line 24}
Specify additional arguments to pass on the command line when a given
partition is launched.

@item @b{Line 25}
Specify a termination mechanism for partition_4. The default is to
compute a global distributed termination. When Local_Termination is
specified then a partition terminates when the local termination is
detected (standard ada termination).

@item @b{Line 27}
Specify the kind of startup method you would like. There are 3
possibilities: Shell, Ada and None. Specifying `Shell' builds a shell
script. All the partitions will be launched from a shell script.  If
`Ada' is chosen, then the main Ada procedure itself is used to launch
the various partitions. If method `None' is chosen, then no launch
method is used and you have to start each partition manually.

If no starter is given, then an Ada starter will be used.

In this example, Partition_2, Partitions_3 and Partition_4 will be
started from Partition_1 (ie from the Ada procedure Master_Procedure).

@item @b{Line 31}
Specify the use of a particular boot server. It is especially useful
when the default port 5555 used by GARLIC is already assigned.

@item @b{Line 33}
It is a bounded error to elaborate a partition of a distributed
program that contains a compilation unit that depends on a different
version of the declaration of RCI library unit than that included in
the partition to which the RCI library unit was assigned. When the
pragma Version is set to False, no consistency check is performed.

@item Lien 36
Declare two channels. Other channels between partitions remain
unknown.

@item @b{Line 38}
Use transparent compression/decompression for the arguments and
results of any remote calls on channel "Channel_1", i.e. between
"Partition_1" and "Partition_4".
 
@item @b{Line 39}
Use filter "My_Own_Filter" on "Channel_2". This filter must be
implemented in a package "System.Garlic.Filters.My_Own_Filter".

@item @b{Line 40}
For all data exchanged between partitions, use the filter "ZIP". (I.e.
for both arriving remote calls as well as for calls made by a
partition.)

@item @b{Line 42}
"Some_Filter" will be used to exchange a filter's parameters between two
partitions. "Some_Filter" itself must be an algorithm that doesn't need
its own parameters to be filtered again!

On all other channels (i.e., for remote calls between partitions
where no channel was declared), filtering is not used.

@item @b{Line 44}
The configuration body is optional. You may have fully described your
configuration in the declaration part.

@item @b{Line 45}
Partition 2 contains two RCI packages RCI_B2 and RCI_B4 and a normal
package. A normal package is not categorized.

@item @b{Line 46}
Partition 3 contains one RCI package RCI_B3

@end enumerate

@node Tracing Facilities, Remote Shell Notes, The Configuration Language, Getting Started With GLADE
@section Tracing Facilities

To trace your application, you can set two environment variables to
true. The variable S_RPC will provide info on what is going on the
execution of remote procedure calls (resolved in System.RPC -
s-rpc.adb). The variable S_PARINT will provide info on partitions and
units status (resolved in System.Partition_Interface -
s-parint.adb). For instance, using sh, bash or zsh, type:

@smallexample
S_RPC=true;    export S_RPC
S_PARINT=true; export S_PARINT
@end smallexample

@node Remote Shell Notes, Filtering, Tracing Facilities, Getting Started With GLADE
@section Remote Shell Notes

To start a partition, the main partition executable executes a remote
shell. Thus you have to make sure that you are authorized to execute a
remote shell on the remote machine. In this case, a first step would
be to add into your $HOME/.rhosts file a line like :
<remote-machine> <your-username>

If you are not authorized at all, you can bypass this problem. All you
have to do is:

@itemize @bullet

@item
Open a session on each machine listed in your configuration file.

@item
If MAIN_PART is the partition that includes the main procedure and if
you want to start MAIN_PART on host MAIN_HOST:

@itemize @bullet

@item
Choose a TCP port number PORT_NUM (gnatdist default is 5555 when using a
shell starter, randomly chosen when using an Ada starter).

@item
Then for each partition PART, start manually the corresponding
executable on the corresponding host as follows

@smallexample
% PART [--nolaunch] [--slave]\
    --boot_server tcp://MAIN_HOST:PORT_NUM
@end smallexample

The --nolaunch parameter must be included for the main partition, it
means that this partition is not in charge of launching others. The
--slave parameter must be included for other partitions, meaning that in
no case the name server is located on them.

@end itemize

@item
If you want to kill the distributed application before it terminates,
kill MAIN_PART.

@end itemize

@node Filtering, Trace/Replay Debugging, Remote Shell Notes, Getting Started With GLADE
@section Filtering

GLADE contains a transparent extensible filtering mechanism allowing the
user to define various data transformations to be performed on the arguments
and return values of remote calls. One possible application would be to
compress all data before sending it and to decompress it on the receiving
partition.

With GLADE, it is no longer necessary that the application take care of such
transformations. Instead, users can write their own data transformations and
hook them into GLADE so that they are automatically and transparently applied
depending on the configuration of the distributed application.

@menu
* Configuring Filtering::       
* Implementing Your Own Filters::  
@end menu

@node Configuring Filtering, Implementing Your Own Filters, Filtering, Filtering
@subsection Configuring Filtering

As a default, no filtering is performed by GLADE. As a default, the
compression filter is available. Therefore, you can configure your
distributed application in order to use this filter.

The configuration language not only knows about partitions, it also
knows about the connections between them. Such a connection is called a
"Channel" and represents a bi-directional link between two
partitions. In order to define filtering, one must first declare the
channels between the partitions of an application:

@smallexample
A_Channel : Channel := (Partition_1, Partition_2);
@end smallexample

This gives the link between partitions "Partition_1" and "Partition_2"
the name "A_Channel". It is not possible to declare more than one
channel between the same two partitions.

Now that this channel is known, the data transformation that is to be
applied on all data sent through it can be defined:

@smallexample
for A_Channel'Filter use "ZIP";
@end smallexample

This specifies that all data sent over this channel should be
transformed by the filter named "ZIP". (There must be a filter with this
name, implemented in the package 'System.Garlic.Filters.Zip'.)

Some filtering algorithms require that some parameters must be sent to the
receiver first to enable it to correctly de-filter the data. If this is
the case, it may be necessary to filter these parameters again. For such
purposes, it is possible to install a global filter for all partitions,
which then will be used to filter the parameters of other filters. This
filter is called the "registration filter". It can be set by a pragma:

@smallexample
pragma Registration_Filter ("Filter_Name");
@end smallexample

It may also be useful to specify that a partition use a certain filter
for all remote calls, regardless of the channel (i.e., regardless of the
partition that'll receive the remote call). This can be specified using
the attribute 'Filter on a partition:

@smallexample
for Partition_1'Filter use "ZIP";
@end smallexample

or even

@smallexample
for Partition'Filter use "ZIP";
@end smallexample

(The latter set the default filter for all partitions of the application,
the former only sets the default filter for the partition "Partition_1".)
It is also possible to apply a default filter and to override this default
for specific channels:

@smallexample
My_Channel : Channel := (Partition_1, Partition_2);

for My_Channel'Filter  use "ZIP";
for Partition_1'Filter use "Some_Other_Filter";
@end smallexample

This makes 'Partition_1' use "Some_Other_Filter" for all remote calls
except for any communication with 'Partition_2', where the filter "ZIP"
is applied.

Gnatdist takes care of consistency checking of a filter definition. By
default, no filtering is done. Filtering is only active if specified
explicitly in the configuration file.
 
@node Implementing Your Own Filters,  , Configuring Filtering, Filtering
@subsection Implementing Your Own Filters

As has been briefly mentioned above, a filter with a name "NAME" must be
implemented in a package called 'System.Garlic.Filters.Name'. You may
write your own filters, which must implement their filtering of data in
the primitive operations of a type derived from the type
'System.Garlic.Filters.Filter_Type'. Your filter package must then
register an instance of your newly derived type with GLADE by calling
'System.Garlic.Filters.Register'. From that on, your filter is ready to
be used.

For more information on how to write your own filter packages see the
sample implementation of a ZIP filter in files 's-gafizi.ad[bs]' in the
distribution. You might also want to look at the example in the
'Filtering' directory of the GLADE distribution.


@node Trace/Replay Debugging, Glade File Hierarchy, Filtering, Getting Started With GLADE
@section Trace/Replay Debugging

GLADE has a facility for trace/replay based debugging. If trace mode
is turned on, GLADE will record all messages received by a partition
into a trace file. The trace file can then be used to replay the
execution of the partition, in isolation.

To get a partition to generate a trace file, it has to be passed the
command line argument "--trace". This is most easily done by using the
"for Partition'Command_Line use..." construct (described above) in the
configuration file to add "--trace" to the command lines of the
partitions whose executions are to be replayed. When the application
has been built, starting it using the starter, as usual, will then
result in the trace files being generated.

By default, the file name of the trace file is the name of the
partition's executable (i.e. the string returned by the standard
procedure Ada.Command_Line.Command_Name) with a trailing
".trace". This can be changed with the "--trace_file othername"
command line argument. Note that since the remote partitions are
launched with rsh under Unix, the current directory during execution
will be the user's home directory. This is no problem when using the
default trace file name, because the executable's name will include
the absolute path. When using the "--trace_file" option, on the other
hand, if you don't want the trace file to be created/read in the home
directory, the absolute path will have to be included in the desired
name.

In order to replay a partition whose execution has been previously
traced, the command line argument "--replay" is required. In addition,
the special boot server location "replay://" has to be specified,
i.e. by using the "--boot_server replay://" command line argument.

Example: To replay a traced execution of partition whose executable is
named PART, you would start it with the command

@smallexample
% PART [--nolaunch] [--slave] --replay --boot_server replay://
@end smallexample

possibly under the control of a debugger, such as gdb.

Since the exact contents of the messages received is recorded,
differences in input from external sources (such as standard input)
during replay will most likely give unexpected results. Also, replay
of applications whose behavior is inherently non-deterministic will be
problematic.

N.B. It is important that the same executable is used for replay as
when the trace file was generated, otherwise strange behavior can be
expected.

@node Glade File Hierarchy, GLADE Internals, Trace/Replay Debugging, Getting Started With GLADE
@section Glade File Hierarchy

All GLADE intermediate files (object files, etc) are stored under a
common directory named "dsa". You may remove this whole directory and
its content when you do not intend to rebuild your distributed
applications.

@node GLADE Internals,  , Glade File Hierarchy, Getting Started With GLADE
@section GLADE Internals

The GLADE PCS is called GARLIC which stands for Generic Ada Reusable
Library for Interpartition Communication. Most of the previous features
like filtering, trace / replay, termination, reconnection, version
consistency and remote launching are provided via GARLIC specific
features. Some of these features are not configurable by the user.

@menu
* Heterogeneous Systems::       
* Multiple Requests::           
* Priority Inheritance::        
* Remote Procedure Call Abortion::  
@end menu

@node Heterogeneous Systems, Multiple Requests, GLADE Internals, GLADE Internals
@subsection Heterogeneous Systems

The GNAT environment provides default attributes except for non remote
access types (see section @ref{Transmitting Dynamic Structure} and
@ref{}). The implementation of the default attributes of predefined
types can be found in @t{System.Stream_Attributes}.

The GLADE installation overloads the GNAT default marshalling and
unmarshalling subprograms by its own subprograms which format data
according to a @i{XDR}-like protocol. Therefore, any GLADE application
will work in an heterogeous environment.

If the user wants to keep working with the GNAT default attributes for
performance purposes or to use another protocol to marshall and
unmarshall predefined types, he can replace @t{s-stratt.adb} by his own
implementation.

@node Multiple Requests, Priority Inheritance, Heterogeneous Systems, GLADE Internals
@subsection Multiple Requests
When multiple remote procedure calls occur on the same partition, they
are handled by several anonymous tasks. The number of tasks in the
anonymous tasks pool can be configured by three figures (see section
@ref{Anonymous Tasks Pool}). Therefore, the user may have to synchronize 
global data in the Remote_Call_Interface or Remote_Types unit to
preserve concurrent access on data. If the user want to suppress the
multiple requests features, he can force the configuration of the
anonymous tasks pool to (0 | 1, 0 | 1, 1). That means that there is at
most one anonymous task running at a time.

@node Priority Inheritance, Remote Procedure Call Abortion, Multiple Requests, GLADE Internals
@subsection Priority Inheritance
It is compiler-dependent to preserve the caller priority during a remote
procedure call. In fact, it can be unsafe because two partitions may
have different priority range and policy. Nevertheless, GLADE preserves
the caller priority. This priority is marshalled and unmarshalled during
the remote procedure call and the anonymous task is set to the caller
priority. There is no way yet to suppress this feature.

@node Remote Procedure Call Abortion,  , Priority Inheritance, GLADE Internals
@subsection Remote Procedure Call Abortion
When a remote procedure call is aborted, GLADE will abort the calling
task on the caller side. But it will also try to abort the remote
anonymous task performing the remote call. This task will be aborted
without being requeued in the anonymous tasks pool.

@c @node
@c @section Restrictions

@c Static remote procedures, asynchronous remote procedures, remote
@c access to class wide types, remote access to subprogram and
@c asynchronous transfer of control with remote procedures are
@c implemented. Remote types packages are implemented.

@c Pragma All_Calls_Remote has been implemented.

@c Shared passive packages are unimplemented.

@c Language-defined exceptions propagate well through different
@c partitions.

@node DSA and CORBA,  , Getting Started With GLADE, Top
@appendix DSA and CORBA



@menu
* CORBA Architecture::          
* Interface Definition Language::  
* Network Communication Subsystem::  
* Distributed Application Development::  
* Some Elements of Comparison::  
@end menu

@node CORBA Architecture, Interface Definition Language, DSA and CORBA, DSA and CORBA
@section CORBA Architecture

CORBA is an industry-sponsored effort to standardize the distributed
object paradigm via the CORBA Interface Definition Language (IDL).  The
use of IDL makes CORBA more self-describing than any other client/server
middleware. The Common Object Request Broker: Architecture and
Specification, revision 2.2 describes the main features of CORBA which
are Interface Definition Language, Language Mappings, Stubs, Skeletons
and Object Adapters, ORB, Interface Repository, Dynamic Invocation, ORB
protocols and CORBA services.

@image{corba-arch.fig}

The IDL specifies modules, constants, types and interfaces. An object
interface defines the operations, exceptions and public attributes a
client can invoke or access. CORBA offers a model based only on
distributed objects. In some respects, it can be compared to Java as
this language provides only an object-oriented programming model, and
discards the classical structured programming model.

An IDL translator generates client stubs and server skeletons in a host
language (@t{C++}, @t{C}, Java, Smalltalk, Ada95); a language mapping
specifies how IDL entities are implemented in the host
language. Depending on the features available in the host language, the
mapping can be more or less straightforward.  When an IDL feature is not
defined in the host language, the mapping provides a standardized but
complex way of simulating the missing feature.  Although the user works
with the generated code, a good understanding of the language mapping is
often necessary.

When the host language does not provide object-oriented features, the
user has to deal with a complex simulation of those functions. A @t{C++}
programmer has to follow several rules related to parameters passed by
reference. Defining whether the callee or the caller is responsible for
parameter memory allocation can be considered as @t{C++} programming
conventions. The most difficult parts of the Ada mapping, that an Ada
programmer should avoid when possible, are multiple inheritance and
forward declarations.

The IDL translator produces several host language source files depending
on the language mapping: client files called stubs and server files
called skeletons. These files are specific to a vendor and product, as
they make calls to a proprietary communication subsystem, but their
structure and interface are supposed to follow a standard canvas.  The
client stubs convert user queries into requests to the ORB, which
transmits these requests through an object adapter to the server
skeleton.

@node Interface Definition Language, Network Communication Subsystem, CORBA Architecture, DSA and CORBA
@section Interface Definition Language

In DSA, the IDL is a subset of Ada95. The user identifies at compile
time interface packages. Some library-level packages are categorized
using pragmas and these interface packages have to be unit
libraries.

In CORBA, the IDL is a descriptive language; it supports @t{C++}
syntax for constant, type and operation declarations. From IDL
descriptions, a translator can directly generate client header files
and server implementation skeletons.

An IDL file starts by defining a module. This provides a name space to
gather a set of interfaces. This is a way to introduce a level of
hierarchy whose designation looks like
(<@t{module}>::<@t{interface}>::<@t{operation}>). The Ada95 binding maps
this element into a (child) package.  @t{#include} statements make any
other name spaces visible.

An IDL file can start by defining a module. This provides a name-space
to gather a set of interfaces. This is a way to introduce a level of
hierarchy (<@i{module}>::<@i{interface}>::<@i{operation}>). The Ada95
binding maps this element into a (child) package. @t{#include}
will make any other namespaces visible.

A module can define interfaces. An interface defines a set of methods
that a client can invoke on an object. An interface can also define
exceptions and attributes. An exception is like a @t{C++} exception: a
data component can be attached to it. An attribute is a component
field. For each @i{Attribute}, the implementation automatically creates
the subprograms Get_@i{Attribute} and Set_@i{Attribute}. Only Get is
provided for @i{readonly} attributes. An interface can derive from one
or more interfaces (multiple inheritance).

The Ada~95 binding maps this element into a package or a child
package. For the client stub, the implementation will automatically
create a tagged type named Ref (which is derived from CORBA.Object.Ref
or from another Ref type defined in another interface) in a package
whose name matches the one of the interface. For the server skeleton,
the implementation will automatically create a tagged type named
Object (which is derived from an implementation defined private tagged
type Object) in a package named Impl, which is a child package of a
package named after the interface name (<@i{interface}>.Impl).

@include naming.idl.texi

A method is defined by a unique name (no overloading is allowed) and its
signature (the types of its formal parameters). Each parameter can be of
mode @b{in}, @b{out} or @b{inout}, whose meanings are comparable to
their Ada homonyms. Every exception that can be raised by a method must
also be declared as part of the method signature.

The @b{oneway} attribute can be applied to a subprogram, giving it
at-most-once semantics instead of the exactly-once default.
This precludes a method from having output parameters, a return
value, or raised exception. It is not portable to assume that the caller
resumes its execution once the input parameters are sent.

Most CORBA data types map in a straightforward way onto predefined Ada
types, with the exception of @t{any} and @t{sequence}.  @t{any}, that
can designate any CORBA type, is mapped onto a stream type with @t{read}
and @t{write} operations. A @t{sequence} holds a list of items of a
given type and is represented in Ada using a pair of lengthy generic
packages. One may note that the CORBA @t{string} type is mapped onto the
@t{Unbounded_String} Ada95 type. The IDL does not provide an equivalent
to unconstrained arrays.

The Ada95 mapping provides special mechanisms to implement two
difficult-to-map CORBA features. First, it provides a translation of
multiple inheritance. As described above, an Ada95 package defines a
type derived from the first interface, and extends the list of its
primitive operations to achieve inheritance from other
interfaces. Another unnatural feature of CORBA for an Ada programmer
comes from forward declarations. In Ada, two package specifications
cannot ``with'' each others, but this can occur between two IDL
interfaces.  To solve this, the mapping proposes to create ``forward''
packages.  This can result in a very non-intuitive situation where the
client stub does not ``with'' its usual interface packages but
``forward'' packages instead.

When developping a distributed application with CORBA, two situations
may appear. On the server side, the programmer is responsible for the
IDL file. He has to understand the Ada95 language mapping in order to
avoid structures with a non-trivial implementation whenever possible,
such as forward declaration and multiple inheritance. On both the server
and the client side, the programmer has to deal with the generated
code. A good understanding of the mapping is useful to get back and
forth from the IDL file to the generated code in order to keep an
overview of the distributed application. Understanding this mapping can
be a tedious task depending of the host language.

IDL interface information can be stored on-line in a database called
Interface Repository (IR). A CORBA specification describes how the
interface repository is organized and how to retrieve information from
it.  The reader will note that this information is close to what the Ada
Semantic Interface Specification can provide.

The interface repository allows a client to discover the signature of a
method which it did not know at compile time. It can subsequently use
this knowledge together with values for the method's parameters to
construct a complete request and invoke the method. The set of functions
that permits the construction of a method invocation request at run time
is the Dynamic Invocation Interface (DII).

The IR API allows the client to explore the repository classes to obtain
a module definition tree. From this tree, the client extracts subtrees
defining constants, types, exceptions, and interfaces. From an interface
subtree, the client can select an operation with its list of parameters
(type, name and mode) and exceptions.

A client has then three ways to make a request. As in the static case,
he can send it and wait for the result; he can also may a one-way call
and discard the result. With dynamic requests, a third mechanism is
offered: the client can send the request without waiting for the result,
and obtain it later, asynchronously.

The DII has a server-side counterpart, called Dynamic Skeleton
Interface. Both mechanisms are powerful but very complex and tedious to
use. In some respects, they also violate the Ada~95 philosophy, because
strong typing is not preserved.  Most users will keep working with
static invocations.

@node Network Communication Subsystem, Distributed Application Development, Interface Definition Language, DSA and CORBA
@section Network Communication Subsystem

The communication subsystem is one of the key points of a
distributed system: it offers basic services such as the capability to
transmit a message from one part of the distributed program to
another. Those elementary services are then used by higher level
services to build a fully functional distributed system.

The limit between what belongs to the communication subsystem and what
belongs to an external service may sometimes be difficult to draw.
Moreover, something considered as a service in CORBA may be viewed as
purely internal in DSA.

@menu
* DSA PCS::                     
* CORBA ORB::                   
@end menu

@node DSA PCS, CORBA ORB, Network Communication Subsystem, Network Communication Subsystem
@subsection DSA PCS

In the DSA world, everything that is not done by the compiler in
regard to the distribution belongs to the partition communication
subsystem (PCS). For example, figuring out on which partition a package
that will be called remotely is located is part of the PCS's
responsibility.

The PCS entry points are well defined in DSA, and described in the
@t{System.RPC} package declaration.  By looking at this package,
one can notice that there is nothing related to abortion of remote
subprogram calls, although the Annex states that if such a call is
aborted, an abortion message must be sent to the remote partition to
cancel remote processing. That means that the PCS is in charge of
detecting that a call to one of its entry points has been aborted and
must send such an abortion message, without any help from the
compiler.

Another interesting characteristic of the PCS is its behavior regarding
unknown exceptions. When an exception is raised as a result of the
execution of a remote subprogram call, it is propagated back to the
caller. However, the caller may not have any visibility over the
exception declaration, but may still catch it with a @t{when
  others} clause. But if the caller does not catch it and let it be
propagated upstream (maybe in another partition), and if the upstream
caller has visibility over this exception, it must be able to catch it
using its name. That means that the PCS must recognize that a
previously unknown exception maps onto a locally known one, for
example by being able to dynamically register a new exception into the 
runtime.

@node CORBA ORB,  , DSA PCS, Network Communication Subsystem
@subsection CORBA ORB

In CORBA, a much more fragmented approach of services was adopted:
they are essentially defined externally.  For example, the naming
service (which maps object names to object references) is a
distributed object with a standard IDL interface.

While this approach seems more pure, it has performance drawbacks.
Being itself a distributed object, the naming service cannot be
optimized for the needs of a specific ORB. A special case is also
required in the ORB for it to be able to locate the naming service
itself (chicken and egg problem): in order to get a reference on a
distributed object (an IOR, Interface Object Reference) to start with,
the programmer needs to have an IOR for the naming service.  This IOR
can be retrieved from the command line, from a file or by invoking the
ORB Interface, depending on the CORBA version.

Regarding exception propagation, an ORB is not able to propagate an
exception that has not been declared in the IDL interface. This
restriction, although annoying because it restricts the usage of
exceptions, is understandable given the multi-language CORBA approach:
what should be done, for example, when a @t{C++} exception reaches a
caller written in Ada? Note that an implementation may provide more
information in the CORBA exception message, such as the @t{C++} or Ada
exception name.

@node Distributed Application Development, Some Elements of Comparison, Network Communication Subsystem, DSA and CORBA
@section Distributed Application Development



@menu
* DSA Application Development::  
* CORBA Application Development::  
@end menu

@node DSA Application Development, CORBA Application Development, Distributed Application Development, Distributed Application Development
@subsection DSA Application Development

The DSA does not describe how a distributed application should be
configured. It is up to the user (using a partitioning tool whose
specification is outside the scope of the annex) to define what the
partitions in his program are and on which machines they should be
executed.

GLADE provides a Configuration Tool and a Partition Communication
Subsystem to build a distributed application. The GNATDIST tool and its
configuration language have been specially designed to let the user
partition his program and specify the machines where the individual
partitions will be executing. The Generic Ada Reusable Library for
Interpartition Communication (GARLIC) is a high level communication
library that implements the interface between the Partition
Communication Subsystem defined in the Reference Manual and the network
communication layer with object-oriented techniques.

@node CORBA Application Development,  , DSA Application Development, Distributed Application Development
@subsection CORBA Application Development

The ORB provides a core of basic services. All other services are
provided by objects with IDL. The OMG has standardized a set of useful
services like Naming, Trading, Events, Licensing, Life Cycle, Events,
... A CORBA vendor is free to provide an implementation of these
services.

The Naming Service allows the association (@i{binding}) of an
object reference with user-friendly names. A name binding is always
defined relative to a @i{naming context} wherein it is unique. A
naming context is an object itself, and so can be bound to a name in
another naming context. One thus creates a @i{naming graph}, a
directed graph with naming contexts as vertices and names as edge
labels. Given a context in a naming graph, a sequence of names can
thus reference an object. This is very similar to the naming
hierarchies that exist in the Domain Name System and the UNIX file
system. A typical scenario consists in providing a well-known remote
reference that defines the root of a naming and naming context
hierarchy and in executing naming operations on this hierarchy. The
Trading Service provides a higher level of abstraction than the Naming
Service. If the Naming Service can be compared to the White Pages, the
Trading Service can be compared to the Yellow Pages.

The Events service provides a way for servers and clients to interact
through asynchronous events between anonymous objects. A @i{supplier}
produces events when a @i{consumer} receives notification and data. An
@i{event channel} is the mediator between consumers and
suppliers. @i{consumer admins} and @i{supplier admins} are in charge of
providing @i{proxies} to allow consumers and suppliers to get access to
the event channel. Suppliers and consumers produce and receive events
through their associated proxies. From the event channel point of view,
a @i{proxy supplier} (or @i{proxy consumer}) is seen as a consumer (or a
supplier).  Therefore, a proxy supplier (or proxy consumer) is an
extended interface of consumer (or supplier). The Events service defines
@i{push} and @i{pull} methods to exchange events. This allows to
define four models to exchange events and data.

@c \reviewers{We shall give more details on the distributed
@c   application development in the final paper. This will also describe
@c   the services available in CORBA: CosNaming, CosEvents,
@c   ...}

@node Some Elements of Comparison,  , Distributed Application Development, DSA and CORBA
@section Some Elements of Comparison

CORBA provides an outstanding and very popular framework. The IDL syntax
is close to @i{C++}. The object model is close to Java: CORBA defines
only distributed objects. Furthermore, when using the Ada mapping, the
stub and skeleton generated code is close to Java with two root classes,
Ref for clients and Object for servers.

DSA provides a more general model. This includes distributed objects,
but also regular remote subprograms and references to remote
subprograms. Shared passive packages can be defined as an abstraction
for a (distributed) shared memory, a persistency support or a database.
Basically, the IDL is a subset of Ada95 and the remote services are
defined in packages categorized by three kinds of pragmas (RCI, RT,
SP). The distributed boundaries are more transparent as the application
is not split into IDL and host language sources.  host languages.

In DSA, any Ada type can be used except access types, but this can be
solved by providing the marshalling operations for such a type. The
exception model is entirely preserved. Overloading is allowed in DSA
(not in CORBA). The user can also define generic packages and use mixin
mechanism to obtain some kind of multiple inheritance.

The DSA user can design, implement and test his application in a
non-distributed environment, and then switch to a distributed situation.
With this two-phase design approach, the user always works within his
favorite Ada95 environment. The use of pragma All_Calls_Remote also
facilitates debugging of a distributed application in a non-distributed
context.

To work on client stubs or server skeletons, the CORBA user will have to
deal with generated code. In any case, understanding the host language
mapping is always very useful. It can be required for some languages
like @i{C++}. An Ada programmer should avoid using forward declaration
or multiple inheritance (and in some respects, sequence).

The CORBA user has to re-adapt his code to the code generated by the
translator from the IDL file anytime the latter is modified. He also has
to use the predefined CORBA types instead of Ada standard types; he has
to call ORB functions or a naming service to obtain remote object
references.

As Ada95 is its own IDL, the user does not deal with any generated stub
or skeleton code. The configuration environment takes care of updating
object, stub and skeleton files when sources have been updated. The
system automatically provides some naming functions like declaring RCI
services. It also takes care of aborting remote procedure calls,
detecting distributed termination, checking version consistency between
clients and servers, and preserving and propagating any remote
exception.

The RM does not require a DSA implementation to work on heterogeneous
systems but GLADE, like any reasonable implementation, provides default
XDR-like marshalling operations. This feature can be inhibited for
performance reasons. An ORB is required to implement a Common Data
Representation (CDR) to ensure safe communications between heterogeneous
systems.

CORBA is a very rich but very complex standard. Its drawbacks include
the high learning curve for developing and managing CORBA applications
effectively, performance limitations, as well as the lack of portability
and security. These drawbacks are the price to pay for language
interoperability, a facility the Ada~95-oriented DSA does not provide.

Interoperability between compilers is not yet an issue with DSA because
there is only one implementation available (GLADE). But it is a
validation requirement to permit a user to replace his current PCS with
a third-party PCS. We can note this issue was not resolved in CORBA
until revision 2.2. For the same reasons, we can expect future DSA
implementations to ensure PCS compatibility.

Using its IDL, the OMG has described a number of @t{Common Object
  Services} (COS) that are frequently needed in distributed
systems. Unfortunately, these specifications are limited to IDL
descriptions, and most of the semantics are up to the vendor. The DSA
misses such user-level libraries, including basic distributed software
components.  More generally, the lack of component libraries has always
been a problem for Ada.

Implementing CORBA services as native Ada95 distributed objects, taking
advantage of the standard language features, yields a simpler, easy to
understand and use specification. We have already implemented the Naming
service, the Events service and a service close to the Concurrency one
with DSA. Developping the CORBA services was an interesting experience.
We realized that although those services are nicely specified by an IDL
file, their semantics is quite vague in such a way portability is
dramatically broken. This work will be described in a future paper.

Another major goal of the GLADE team is to export DSA services to the
CORBA world.

The idea is to translate all DSA features to equivalent IDL features
using ASIS. This would allow a DSA user to connect his DSA server to an
ORB. This would also allow applications written in other languages to
invoke DSA features. We are also seeking to use this approach to offer a
DII mechanism for DSA.



@c XXXXX Index is nonexistent
@c @node
@c @unnumbered Index

@c @printindex cp

@contents

@bye
